{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Concatenate, Conv1D, MaxPooling1D, Flatten, Embedding, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from textblob import TextBlob\n",
    "import yfinance as yf\n",
    "import talib\n",
    "\n",
    "# Set up API credentials for news sentiment analysis\n",
    "RAPIDAPI_KEY = \"62a5337beamsh4b06b153b683dcep1db8cfjsn6419e7690224\"\n",
    "RAPIDAPI_HOST = \"apidojo-yahoo-finance-v1.p.rapidapi.com\"\n",
    "RAPIDAPI_URL = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/news/v2/get-details\"\n",
    "\n",
    "# Set up stock symbol and time window for data retrieval\n",
    "stock_symbol = \"MSFT\"\n",
    "time_window = \"10y\"\n",
    "\n",
    "# Set up sliding window parameters\n",
    "window_size = 10\n",
    "stride = 1\n",
    "\n",
    "# Define function to retrieve stock data using Yahoo Finance API\n",
    "def get_stock_data(symbol, window):\n",
    "    # Download stock data from Yahoo Finance API\n",
    "    df = yf.download(symbol, period=window, interval=\"1d\", group_by='ticker')\n",
    "    # Drop any rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    # Return DataFrame\n",
    "    return df\n",
    "\n",
    "# Define function to retrieve news sentiment data using Yahoo Finance API\n",
    "def get_news_sentiment_data(symbol, num_articles):\n",
    "    # Set up query parameters\n",
    "    querystring = {\"symbols\": symbol, \"count\": num_articles}\n",
    "    # Set up headers\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": RAPIDAPI_KEY,\n",
    "        \"X-RapidAPI-Host\": RAPIDAPI_HOST\n",
    "    }\n",
    "    # Send request to Yahoo Finance API\n",
    "    response = requests.request(\"GET\", url=RAPIDAPI_URL, headers=headers, params=querystring)\n",
    "    # Parse response as JSON\n",
    "    response_json = response.json()\n",
    "    # Extract sentiment scores for each article\n",
    "    sentiment_scores = []\n",
    "    for article in response_json[\"data\"][symbol][\"news\"]:\n",
    "        text = article[\"summary\"]\n",
    "        if text:\n",
    "            blob = TextBlob(text)\n",
    "            sentiment_scores.append(blob.sentiment.polarity)\n",
    "    # Return list of sentiment scores\n",
    "    return sentiment_scores\n",
    "\n",
    "# Define function to retrieve technical indicator data using TA-Lib library\n",
    "def get_technical_indicator_data(df):\n",
    "    # Calculate technical indicators\n",
    "    df[\"rsi\"] = talib.RSI(df[\"Close\"])\n",
    "    df[\"macd\"], _, _ = talib.MACD(df[\"Close\"])\n",
    "    df[\"cci\"] = talib.CCI(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    # Drop any rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    # Normalize technical indicator data\n",
    "    scaler = MinMaxScaler()\n",
    "    df[[\"rsi\", \"macd\", \"cci\"]] = scaler.fit_transform(df[[\"rsi\", \"macd\", \"cci\"]])\n",
    "    # Return DataFrame\n",
    "    return df\n",
    "\n",
    "# Retrieve stock data from Yahoo Finance API\n",
    "df_stock = get_stock_data(stock_symbol, time_window)\n",
    "# Retrieve news sentiment data from Yahoo Finance API\n",
    "sentiment_scores = get_news_sentiment_data(stock_symbol, len(df_stock))\n",
    "# Retrieve technical indicator data using TA-Lib library\n",
    "df_stock = get_technical_indicator_data(df_stock)\n",
    "# Define function to create sliding windows of data\n",
    "def create_sliding_windows(data, window_size, stride):\n",
    "    # Initialize empty lists for input/output data\n",
    "    X, y = [], []\n",
    "    # Loop through data to create sliding windows\n",
    "    for i in range(0, len(data) - window_size, stride):\n",
    "        # Select window of data\n",
    "        window = data[i:i + window_size]\n",
    "        # Split window into input/output pairs\n",
    "        X.append(window[:-1])\n",
    "        y.append(window[-1])\n",
    "    # Convert data to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # Return input/output data\n",
    "    return X, y\n",
    "\n",
    "# Create sliding windows of data\n",
    "X_stock, y_stock = create_sliding_windows(df_stock.values, window_size, stride)\n",
    "X_sentiment, y_sentiment = create_sliding_windows(np.array(sentiment_scores).reshape(-1, 1), window_size, stride)\n",
    "\n",
    "# Split data into training/validation/testing sets\n",
    "train_size = int(0.7 * len(X_stock))\n",
    "val_size = int(0.2 * len(X_stock))\n",
    "test_size = len(X_stock) - train_size - val_size\n",
    "\n",
    "X_stock_train = X_stock[:train_size]\n",
    "y_stock_train = y_stock[:train_size]\n",
    "X_sentiment_train = X_sentiment[:train_size]\n",
    "y_sentiment_train = y_sentiment[:train_size]\n",
    "\n",
    "X_stock_val = X_stock[train_size:train_size+val_size]\n",
    "y_stock_val = y_stock[train_size:train_size+val_size]\n",
    "X_sentiment_val = X_sentiment[train_size:train_size+val_size]\n",
    "y_sentiment_val = y_sentiment[train_size:train_size+val_size]\n",
    "\n",
    "X_stock_test = X_stock[-test_size:]\n",
    "y_stock_test = y_stock[-test_size:]\n",
    "X_sentiment_test = X_sentiment[-test_size:]\n",
    "y_sentiment_test = y_sentiment[-test_size:]\n",
    "\n",
    "# Define input layers\n",
    "input_stock = Input(shape=(X_stock.shape[1], X_stock.shape[2]), name=\"stock_input\")\n",
    "input_sentiment = Input(shape=(X_sentiment.shape[1], X_sentiment.shape[2]), name=\"sentiment_input\")\n",
    "\n",
    "# Define LSTM layers for stock data\n",
    "lstm_stock = LSTM(64, activation=\"relu\", return_sequences=True)(input_stock)\n",
    "lstm_stock = Dropout(0.2)(lstm_stock)\n",
    "lstm_stock = LSTM(32, activation=\"relu\")(lstm_stock)\n",
    "lstm_stock = Dropout(0.2)(lstm_stock)\n",
    "\n",
    "# Define Convolutional Neural Network (CNN) layers for sentiment data\n",
    "cnn_sentiment = Conv1D(filters=32, kernel_size=3, activation=\"relu\")(input_sentiment)\n",
    "cnn_sentiment = MaxPooling1D(pool_size=2)(cnn_sentiment)\n",
    "cnn_sentiment = Conv1D(filters=64, kernel_size=3, activation=\"relu\")(cnn_sentiment)\n",
    "cnn_sentiment = MaxPooling1D(pool_size=2)(cnn_sentiment)\n",
    "cnn_sentiment = Flatten()(cnn_sentiment)\n",
    "\n",
    "# Concatenate LSTM and CNN layers\n",
    "concatenated = Concatenate()([lstm_stock, cnn_sentiment])\n",
    "output = Dense(1, activation=\"sigmoid\")(concatenated)\n",
    "\n",
    "# Define model and compile\n",
    "model = Model(inputs=[input_stock, input_sentiment], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Define callbacks for early stopping and saving best model\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\"stock_prediction.h5\", save_best_only=True)\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss=\"mse\")\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=64, callbacks=[early_stop, model_checkpoint])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.load_weights(\"stock_prediction.h5\")\n",
    "mse, _ = model.evaluate(X_test, y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Test set RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot the predicted vs actual prices\n",
    "plt.plot(y_test, label=\"Actual Prices\")\n",
    "plt.plot(y_pred, label=\"Predicted Prices\")\n",
    "plt.title(\"Actual vs Predicted Prices\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price ($)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
